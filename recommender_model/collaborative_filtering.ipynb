{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a02efc9d-19b7-4ca6-9700-0511dd3f804c",
   "metadata": {},
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7583ba8-331c-4238-a061-1ea5b6b35c26",
   "metadata": {},
   "source": [
    "Collaborative Filtering means that interests of other users are taking into account for making a playlist prediction. Spotify uses a matrix where each row is a user and each column is a song, each entry therefore resembles how often a user has listened to a song. Since this data is not publicly available, we will try the same approach, but with a different matrix. The matrix will have one row for each playlist and each column will be a song. The entries of the matrix are going to be 1 if the song is in the playlist and 0 if not. Read more about collaborative filtering [here](TODO)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58a8742-d41c-44e6-902a-54b44fe3acf6",
   "metadata": {},
   "source": [
    "Let's first import all important libraries. pandas DataFrames are used to store the data and numpy arrays for matrix computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c95d708-54b8-46b5-aba1-4d67ee2ceb6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T19:19:50.827376200Z",
     "start_time": "2023-12-01T19:19:50.510096200Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scripts.matrix_factorization import MF  # for matrix factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd66f9e-d69d-45df-9bea-7313a2c8478b",
   "metadata": {},
   "source": [
    "Load the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afcfff27-de33-4652-921b-b54ea63ef93a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T19:19:51.219933100Z",
     "start_time": "2023-12-01T19:19:50.827376200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a dataset of 64574 entries\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/sorted_processed_data_train.csv\")\n",
    "print(f\"We have a dataset of {len(df)} entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98caa4d1-e629-4226-9411-2daca9d4d2f4",
   "metadata": {},
   "source": [
    "We want to build a matrix where each row is a playlist, and each column resembles a song. The dimensions of our matrix resemble those of the playlist number and track number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "342b3e17-8e31-4e01-bd64-93c6f340b46b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T19:19:51.239765400Z",
     "start_time": "2023-12-01T19:19:51.219933100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playlists: 833 \n",
      "Tracks: 29384\n"
     ]
    }
   ],
   "source": [
    "num_playlists = df[\"name\"].nunique()  # count distinct values, this is the number of playlists\n",
    "num_tracks = df[\"track_name\"].nunique()  # count distinct values, this is the number of tracks\n",
    "print(f\"Playlists: {num_playlists} \\nTracks: {num_tracks}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cedca0-becd-4437-be08-16dc9453a4ea",
   "metadata": {},
   "source": [
    "Group the data by the playlist name. This results in a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d330301-389c-42e0-823d-a97311de9288",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T19:19:51.330195Z",
     "start_time": "2023-12-01T19:19:51.239765400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "name\n CHiLl         [Fresh Eyes, i hate u, i love u (feat. olivia ...\n Frozen        [Queen Elsa of Arendelle - Score Demo, Reindee...\n indie rock    [Back In Your Head, Be Good (RAC Remix), Bambi...\n#Relaxed       [Bag Lady, On & On, I Can't Stop Loving You, L...\n#Workout       [Can't Feel My Face - Martin Garrix Remix, Ign...\nName: track_name, dtype: object"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlists = df.groupby('name')[\"track_name\"].apply(list)\n",
    "playlists.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8ad424-cc62-4e46-9ff6-48c9d3ce57d2",
   "metadata": {},
   "source": [
    "We need a list of the unique songs to create each playlist vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fefb3df-470d-4f25-ad97-b48066dc215b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T19:19:51.330195Z",
     "start_time": "2023-12-01T19:19:51.271023400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique songs: 29384\n"
     ]
    }
   ],
   "source": [
    "unique_songs = list(df[\"track_name\"].unique())  # list of unique songs, maps each song to an index\n",
    "print(f\"Number of unique songs: {len(unique_songs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f1ccdb-ef56-4194-af5e-c76992c670f2",
   "metadata": {},
   "source": [
    "We can now iteratively build our matrix by creating each playlist in a vector of its songs. This is done by one-hot encoding, meaning every column is a song, and every row a playlist, and the row-column combination is one if the song was added to the playlist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a951f61b-4e6f-4b76-85ba-b7fbf9b3d1c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T19:19:55.057045500Z",
     "start_time": "2023-12-01T19:19:51.284402300Z"
    }
   },
   "outputs": [],
   "source": [
    "one_hot_playlists = list()\n",
    "for playlist in playlists:\n",
    "    playlist_array = np.zeros(num_tracks)\n",
    "    for song in playlist:\n",
    "        playlist_array[unique_songs.index(song)] = 1  # set array to 1 at index of the song\n",
    "    one_hot_playlists.append(playlist_array)\n",
    "one_hot_playlists = np.array(one_hot_playlists)  # convert to one numpy array (matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29018e9-801a-44a2-9418-ab7c3b6311d9",
   "metadata": {},
   "source": [
    "For example, the first playlist \"CHiLl\" includes the song \"Make Me (Cry)\" and does not include \"Mr. Brightside\". Check if the value is one and zero respectively at the corresponding positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59f6585c-4e8b-4b17-8127-ddc24ae7a9c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T19:19:55.072681300Z",
     "start_time": "2023-12-01T19:19:55.072163300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(one_hot_playlists[0][unique_songs.index(\"Make Me (Cry)\")] == 1.0)\n",
    "print(one_hot_playlists[0][unique_songs.index(\"Mr. Brightside\")] == 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957ca396-6acf-4a39-9527-2dee2b5b7471",
   "metadata": {},
   "source": [
    "The shape of our playlists should be playlist number times distinct track number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "275e7098-446a-4799-afd2-43be31d0b27e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T19:19:55.087352800Z",
     "start_time": "2023-12-01T19:19:55.072681300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(833, 29384)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_playlists.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9cba86-6cda-4456-a0ae-a66b423ffe87",
   "metadata": {},
   "source": [
    "We now apply matrix factorization on our data. This means, we try to find two matrices, which multiplied are as close to the original matrix as possible. We train using gradient descent, meaning we try to minimize the error in each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c3a9b53-ce9b-48f2-946e-e8a69a3389d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T19:21:42.041548500Z",
     "start_time": "2023-12-01T19:19:55.087352800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; error = 2.1155\n",
      "Iteration: 20 ; error = 1.1530\n",
      "Iteration: 30 ; error = 0.7647\n",
      "Iteration: 40 ; error = 0.5546\n",
      "Iteration: 50 ; error = 0.4267\n",
      "Iteration: 60 ; error = 0.3408\n",
      "Iteration: 70 ; error = 0.2765\n",
      "Iteration: 80 ; error = 0.2321\n",
      "Iteration: 90 ; error = 0.1969\n",
      "Iteration: 100 ; error = 0.1673\n"
     ]
    },
    {
     "data": {
      "text/plain": "[(0, 15.295526520377306),\n (1, 8.377218879031965),\n (2, 5.834762190446305),\n (3, 4.557920102193173),\n (4, 3.760484254323002),\n (5, 3.2188950014340665),\n (6, 2.8396133221875415),\n (7, 2.5422054537340264),\n (8, 2.3147908110243582),\n (9, 2.115548275804261),\n (10, 1.970929788054907),\n (11, 1.818285740833489),\n (12, 1.6992442439892712),\n (13, 1.5895652702434653),\n (14, 1.499103205963745),\n (15, 1.4164011478723069),\n (16, 1.3395150733582029),\n (17, 1.2702212053383057),\n (18, 1.2063403710806984),\n (19, 1.1529861114380264),\n (20, 1.1005930957979086),\n (21, 1.0511870356714754),\n (22, 1.002157978870854),\n (23, 0.9671003053577073),\n (24, 0.9237745039057815),\n (25, 0.8890992072866498),\n (26, 0.8519255032738529),\n (27, 0.8233356365084263),\n (28, 0.7919509679083936),\n (29, 0.7647067113001538),\n (30, 0.7371832047002738),\n (31, 0.7141744922060613),\n (32, 0.6870928233026763),\n (33, 0.6724193711969266),\n (34, 0.6472667350298804),\n (35, 0.6257651187469201),\n (36, 0.607141264780451),\n (37, 0.5885560197090336),\n (38, 0.5711465432675675),\n (39, 0.5545502254263482),\n (40, 0.5397931279410931),\n (41, 0.5244361771718886),\n (42, 0.5146395719780236),\n (43, 0.49681755790412785),\n (44, 0.48962715388953787),\n (45, 0.47452118958803274),\n (46, 0.45843536420312675),\n (47, 0.4472002346647487),\n (48, 0.43726194317164396),\n (49, 0.4266810973468305),\n (50, 0.4150207887464572),\n (51, 0.40635737075106837),\n (52, 0.39592414322601316),\n (53, 0.39163322298956743),\n (54, 0.3775158043223635),\n (55, 0.3733017100920421),\n (56, 0.3611340528450624),\n (57, 0.3536888825920597),\n (58, 0.3457418097801653),\n (59, 0.34078904954007744),\n (60, 0.3310782302258571),\n (61, 0.3247498285259685),\n (62, 0.32004153748353525),\n (63, 0.31111139560323775),\n (64, 0.30682849654913563),\n (65, 0.2987150720941242),\n (66, 0.2946483133580335),\n (67, 0.28880694840316096),\n (68, 0.282315805341795),\n (69, 0.2764850783591115),\n (70, 0.27453558135786316),\n (71, 0.26604972041701463),\n (72, 0.2605130782204438),\n (73, 0.25606644628052866),\n (74, 0.25200810010582253),\n (75, 0.247968888774752),\n (76, 0.2429895678122066),\n (77, 0.23950837726486768),\n (78, 0.23413653622156014),\n (79, 0.2321090235505048),\n (80, 0.22622012418310367),\n (81, 0.22233252901284462),\n (82, 0.21840454793887903),\n (83, 0.21440104248951872),\n (84, 0.21104126383990032),\n (85, 0.20797818749773742),\n (86, 0.2047368942923785),\n (87, 0.20150700327538243),\n (88, 0.19762758087732837),\n (89, 0.19692493199021915),\n (90, 0.19221051274974554),\n (91, 0.18826667056844307),\n (92, 0.1871614474327644),\n (93, 0.18266058125407714),\n (94, 0.1803860924045774),\n (95, 0.1777540853307425),\n (96, 0.17475069863650225),\n (97, 0.17222608366078448),\n (98, 0.1695336485180323),\n (99, 0.16734215306923056)]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf = MF(one_hot_playlists, K=2, alpha=0.1, beta=0.01, iterations=100)\n",
    "mf.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb05f028-ab55-424c-b3a2-6c3e58ec4853",
   "metadata": {},
   "source": [
    "As a result, we get a matrix where values should be close to their original values, but unknown values, in our case songs that are not in the playlist, are approximated by the matrix factorization. For example, if we look at the same song from earlier, the value is close to 1. Looking in at a song that has not been added to the playlist, the value is now approximated to how likely it should be added to the playlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff6b9be8-66fb-4bb3-9baf-88720a57938f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T19:21:42.395029600Z",
     "start_time": "2023-12-01T19:21:42.049461700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9993663650257003\n",
      "1.00004585129019\n"
     ]
    }
   ],
   "source": [
    "print(mf.full_matrix()[0][unique_songs.index(\"Make Me (Cry)\")])\n",
    "print(mf.full_matrix()[0][unique_songs.index(\"Mr. Brightside\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can store our Matrix and use it in the [evaluation notebook](evaluation.ipynb) for making recommendations."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13a7d24b7a52f516"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "with open('data/matrix.npy', 'wb') as f:\n",
    "    np.save(f, mf.full_matrix())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T19:21:42.970669Z",
     "start_time": "2023-12-01T19:21:42.572642900Z"
    }
   },
   "id": "af90f7eea4847d0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save track IDs and playlist names in order to be able to reconstruct the information."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f2dc6c3649ab4f4"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "track_name_to_uri = dict(zip(df.track_name, df.track_uri))\n",
    "unique_songs_uris = [track_name_to_uri[x] for x in unique_songs]\n",
    "\n",
    "with open('data/unique_songs_uris.txt', 'w') as f:\n",
    "\tf.write('\\n'.join(unique_songs_uris))\n",
    "    \n",
    "with open('data/playlists.txt', 'w', encoding=\"utf-8\") as f:\n",
    "\tf.write('\\n'.join(list(playlists.index)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T19:30:56.350153900Z",
     "start_time": "2023-12-01T19:30:56.314881900Z"
    }
   },
   "id": "46e29676bc31e529"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
